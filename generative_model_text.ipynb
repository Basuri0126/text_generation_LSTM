{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L1Ba_bJoxvv",
        "outputId": "714d9f4d-864f-44c6-b4f0-cf4da3f22973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f2_YToY-oZg9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6p-EY0kdo6fk"
      },
      "outputs": [],
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"data_extract.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P5WmKR1bpBbd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIfZPUGqpLpG",
        "outputId": "47ef3f99-863c-49a5-ef10-0068f0c0489a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  482999\n",
            "Total Vocab:  59\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZJ9jLiipTm3",
        "outputId": "96516f5b-8225-4ab4-855a-94ef218c2b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  482899\n"
          ]
        }
      ],
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QV8euW5Hps66"
      },
      "outputs": [],
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m1Mc64Aapz4z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_RKYF6Utp4iM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KLWlCtEp-Pc",
        "outputId": "76b35885-721f-417f-f63e-cad453510255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.8798\n",
            "Epoch 1: loss improved from inf to 2.87977, saving model to weights-improvement-01-2.8798.hdf5\n",
            "3773/3773 [==============================] - 58s 13ms/step - loss: 2.8798\n",
            "Epoch 2/40\n",
            "  10/3773 [..............................] - ETA: 48s - loss: 2.7989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.7439\n",
            "Epoch 2: loss improved from 2.87977 to 2.74391, saving model to weights-improvement-02-2.7439.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.7439\n",
            "Epoch 3/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.6675\n",
            "Epoch 3: loss improved from 2.74391 to 2.66742, saving model to weights-improvement-03-2.6674.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.6674\n",
            "Epoch 4/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.5868\n",
            "Epoch 4: loss improved from 2.66742 to 2.58670, saving model to weights-improvement-04-2.5867.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.5867\n",
            "Epoch 5/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.5085\n",
            "Epoch 5: loss improved from 2.58670 to 2.50847, saving model to weights-improvement-05-2.5085.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.5085\n",
            "Epoch 6/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.4450\n",
            "Epoch 6: loss improved from 2.50847 to 2.44498, saving model to weights-improvement-06-2.4450.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.4450\n",
            "Epoch 7/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.3944\n",
            "Epoch 7: loss improved from 2.44498 to 2.39438, saving model to weights-improvement-07-2.3944.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.3944\n",
            "Epoch 8/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 2.3543\n",
            "Epoch 8: loss improved from 2.39438 to 2.35432, saving model to weights-improvement-08-2.3543.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.3543\n",
            "Epoch 9/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 2.3177\n",
            "Epoch 9: loss improved from 2.35432 to 2.31767, saving model to weights-improvement-09-2.3177.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.3177\n",
            "Epoch 10/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 2.2879\n",
            "Epoch 10: loss improved from 2.31767 to 2.28791, saving model to weights-improvement-10-2.2879.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.2879\n",
            "Epoch 11/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.2595\n",
            "Epoch 11: loss improved from 2.28791 to 2.25947, saving model to weights-improvement-11-2.2595.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.2595\n",
            "Epoch 12/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.2347\n",
            "Epoch 12: loss improved from 2.25947 to 2.23468, saving model to weights-improvement-12-2.2347.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.2347\n",
            "Epoch 13/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 2.2114\n",
            "Epoch 13: loss improved from 2.23468 to 2.21137, saving model to weights-improvement-13-2.2114.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.2114\n",
            "Epoch 14/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.1894\n",
            "Epoch 14: loss improved from 2.21137 to 2.18952, saving model to weights-improvement-14-2.1895.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.1895\n",
            "Epoch 15/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.1708\n",
            "Epoch 15: loss improved from 2.18952 to 2.17083, saving model to weights-improvement-15-2.1708.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.1708\n",
            "Epoch 16/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.1523\n",
            "Epoch 16: loss improved from 2.17083 to 2.15234, saving model to weights-improvement-16-2.1523.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.1523\n",
            "Epoch 17/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.1365\n",
            "Epoch 17: loss improved from 2.15234 to 2.13654, saving model to weights-improvement-17-2.1365.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.1365\n",
            "Epoch 18/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.1201\n",
            "Epoch 18: loss improved from 2.13654 to 2.12015, saving model to weights-improvement-18-2.1201.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.1201\n",
            "Epoch 19/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.1058\n",
            "Epoch 19: loss improved from 2.12015 to 2.10574, saving model to weights-improvement-19-2.1057.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.1057\n",
            "Epoch 20/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.0932\n",
            "Epoch 20: loss improved from 2.10574 to 2.09320, saving model to weights-improvement-20-2.0932.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.0932\n",
            "Epoch 21/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.0807\n",
            "Epoch 21: loss improved from 2.09320 to 2.08073, saving model to weights-improvement-21-2.0807.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0807\n",
            "Epoch 22/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.0699\n",
            "Epoch 22: loss improved from 2.08073 to 2.06989, saving model to weights-improvement-22-2.0699.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0699\n",
            "Epoch 23/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.0583\n",
            "Epoch 23: loss improved from 2.06989 to 2.05831, saving model to weights-improvement-23-2.0583.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0583\n",
            "Epoch 24/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 2.0486\n",
            "Epoch 24: loss improved from 2.05831 to 2.04857, saving model to weights-improvement-24-2.0486.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.0486\n",
            "Epoch 25/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.0394\n",
            "Epoch 25: loss improved from 2.04857 to 2.03936, saving model to weights-improvement-25-2.0394.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0394\n",
            "Epoch 26/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.0313\n",
            "Epoch 26: loss improved from 2.03936 to 2.03130, saving model to weights-improvement-26-2.0313.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0313\n",
            "Epoch 27/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 2.0228\n",
            "Epoch 27: loss improved from 2.03130 to 2.02291, saving model to weights-improvement-27-2.0229.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0229\n",
            "Epoch 28/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.0149\n",
            "Epoch 28: loss improved from 2.02291 to 2.01492, saving model to weights-improvement-28-2.0149.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0149\n",
            "Epoch 29/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 2.0066\n",
            "Epoch 29: loss improved from 2.01492 to 2.00668, saving model to weights-improvement-29-2.0067.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 2.0067\n",
            "Epoch 30/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 2.0014\n",
            "Epoch 30: loss improved from 2.00668 to 2.00142, saving model to weights-improvement-30-2.0014.hdf5\n",
            "3773/3773 [==============================] - 50s 13ms/step - loss: 2.0014\n",
            "Epoch 31/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 1.9936\n",
            "Epoch 31: loss improved from 2.00142 to 1.99365, saving model to weights-improvement-31-1.9936.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9936\n",
            "Epoch 32/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 1.9878\n",
            "Epoch 32: loss improved from 1.99365 to 1.98773, saving model to weights-improvement-32-1.9877.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9877\n",
            "Epoch 33/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 1.9816\n",
            "Epoch 33: loss improved from 1.98773 to 1.98152, saving model to weights-improvement-33-1.9815.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9815\n",
            "Epoch 34/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 1.9753\n",
            "Epoch 34: loss improved from 1.98152 to 1.97533, saving model to weights-improvement-34-1.9753.hdf5\n",
            "3773/3773 [==============================] - 51s 14ms/step - loss: 1.9753\n",
            "Epoch 35/40\n",
            "3773/3773 [==============================] - ETA: 0s - loss: 1.9692\n",
            "Epoch 35: loss improved from 1.97533 to 1.96922, saving model to weights-improvement-35-1.9692.hdf5\n",
            "3773/3773 [==============================] - 52s 14ms/step - loss: 1.9692\n",
            "Epoch 36/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 1.9661\n",
            "Epoch 36: loss improved from 1.96922 to 1.96615, saving model to weights-improvement-36-1.9661.hdf5\n",
            "3773/3773 [==============================] - 51s 14ms/step - loss: 1.9661\n",
            "Epoch 37/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 1.9603\n",
            "Epoch 37: loss improved from 1.96615 to 1.96029, saving model to weights-improvement-37-1.9603.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9603\n",
            "Epoch 38/40\n",
            "3770/3773 [============================>.] - ETA: 0s - loss: 1.9538\n",
            "Epoch 38: loss improved from 1.96029 to 1.95378, saving model to weights-improvement-38-1.9538.hdf5\n",
            "3773/3773 [==============================] - 51s 14ms/step - loss: 1.9538\n",
            "Epoch 39/40\n",
            "3771/3773 [============================>.] - ETA: 0s - loss: 1.9507\n",
            "Epoch 39: loss improved from 1.95378 to 1.95066, saving model to weights-improvement-39-1.9507.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9507\n",
            "Epoch 40/40\n",
            "3772/3773 [============================>.] - ETA: 0s - loss: 1.9462\n",
            "Epoch 40: loss improved from 1.95066 to 1.94618, saving model to weights-improvement-40-1.9462.hdf5\n",
            "3773/3773 [==============================] - 51s 13ms/step - loss: 1.9462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a806a379fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.fit(X, y, epochs=40, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "# Save the final trained model\n",
        "model.save(\"final_model.h5\")\n",
        "\n",
        "# Download the final trained model file\n",
        "files.download(\"final_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EzMW1W4eSw7I",
        "outputId": "fb2aa1fa-789c-422c-a1a6-6f50446c97a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64bbd67c-cc26-47f7-af9a-8074f3ed807a\", \"final_model.h5\", 3382744)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqhze1duGYr"
      },
      "source": [
        "## Generating Text with an LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MZwOL1aIuZyH"
      },
      "outputs": [],
      "source": [
        "filename = \"weights-improvement-40-1.9462.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FjrtzVEqu2-A"
      },
      "outputs": [],
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "pVjxs6fHTP1l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RkJNggQOu48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcf4101-e316-4f66-ec33-61194e710c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" what\n",
            "resembled that of a person who should entertain an idea\n",
            "of committing suicide, and, although be \"\n",
            "leriige the sore of her monher, and to the searen thet were a saaredld to the searen that saeked to be aerere herd and the siale whth the sore of her mother’s siale and searet the searen that sae to meter to the searet that whuh the sore of her mother’s siale and searen thet teeree to be the searet that he had been doen to the sooe of her mother’s siale and searen thet teeree to be the searet that hed mote the sooe of the sore of her mother’s siale and searen thet tee hor to the searen thet was a coefty ceal if hed mote the soaee tfat had been soeer of the sooe and searet and searet of her mother’s sorl, and the searen benne the sooe of the sore of her mother’s siale and searen thet teemed to be the searet that hed mote the sooe of the sore of her mother’s siale and searen thet tee hor to the searen thet was a coefty ceal if hed mote the soaee tfat had been soeer of the sooe and searet and searet of her mother’s sorl, and the searen benne the sooe of the sore of her mother’s siale and \n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "klwztLfLMVyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f118166-dba5-4cf8-f06b-c68197e363cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Perplexity: 6.201847939737958\n"
          ]
        }
      ],
      "source": [
        "def calculate_perplexity(model, X, y):\n",
        "    # Predict probabilities for each character\n",
        "    predictions = model.predict(X, verbose=0)\n",
        "\n",
        "    # Flatten the predictions and true labels\n",
        "    predictions_flat = predictions.reshape(-1, predictions.shape[-1])\n",
        "    y_flat = y.reshape(-1, y.shape[-1])\n",
        "\n",
        "    # Calculate cross-entropy loss\n",
        "    cross_entropy = -np.sum(y_flat * np.log(predictions_flat + 1e-10)) / len(predictions_flat)\n",
        "\n",
        "    # Calculate perplexity\n",
        "    perplexity = np.exp(cross_entropy)\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "# Calculate and print perplexity\n",
        "model_perplexity = calculate_perplexity(model, X, y)\n",
        "print(f\"Model Perplexity: {model_perplexity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKkXXVwBM2Nh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}